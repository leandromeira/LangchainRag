from langchain_google_genai import ChatGoogleGenerativeAI
from search import search_prompt
import os
from dotenv import load_dotenv

load_dotenv()

def main():
    print("=== CHAT RAG - Sistema de Perguntas e Respostas ===")
    print("Digite 'sair', 'quit' ou 'exit' para encerrar o chat\n")
    
    # Inicializar o modelo uma √∫nica vez
    model = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-lite",
        google_api_key=os.getenv("GOOGLE_API_KEY"),
        temperature=0
    )
    print("‚úì Modelo carregado com sucesso!\n")
    
    # Loop principal do chat
    while True:
        try:
            # Obter pergunta do usu√°rio
            user_input = input("PERGUNTA: ").strip()
            
            # Verificar comandos de sa√≠da
            if user_input.lower() in ['sair', 'quit', 'exit', 'q']:
                print("\nüëã Encerrando o chat. At√© logo!")
                break
            
            # Verificar se a pergunta n√£o est√° vazia
            if not user_input:
                print("‚ö†Ô∏è  Por favor, digite uma pergunta v√°lida.\n")
                continue
            
            print(f"\nüîç Processando sua pergunta...")
            
            # Criar chain: busca + prompt + modelo
            chain = search_prompt(user_input) | model

            # Invocar chain
            result = chain.invoke({})
            
            # Exibir resposta
            print("="*60)
            print(f"RESPOSTA: {result.content}")
            print("="*60)
            print()  # Linha em branco para separar as conversas
            
        except KeyboardInterrupt:
            print("\n\nüëã Chat interrompido. At√© logo!")
            break
        except Exception as e:
            print(f"‚ùå Erro: {e}")
            print("Tente novamente com uma pergunta diferente.\n")


if __name__ == "__main__":
    main()
